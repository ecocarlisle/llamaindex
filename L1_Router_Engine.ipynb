{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7c4c87",
   "metadata": {},
   "source": [
    "# Lesson 1: Router Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877df988",
   "metadata": {},
   "source": [
    "Welcome to Lesson 1.\n",
    "\n",
    "To access the `requirements.txt` file, the data/pdf file required for this lesson and the `helper` and `utils` modules, please go to the `File` menu and select`Open...`.\n",
    "\n",
    "I hope you enjoy this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b7267f",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Recommend setting up an environment specifically for this tutorial.  It's always a good idea to create a new environment for each and every project.  I used Anaconda Navigator to create a new \"llamindex\" environment.  If using Anaconda Navigator make sure you install a version of Jupyter notebooks that's lower than 7.0...unless you're already there or not afraid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c97c9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374b748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv==1.0.0\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n"
     ]
    }
   ],
   "source": [
    "### uncomment to pip install\n",
    "#!pip install python-dotenv==1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "897221c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index==0.10.27\n",
      "  Downloading llama_index-0.10.27-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index==0.10.27)\n",
      "  Downloading llama_index_agent_openai-0.2.5-py3-none-any.whl.metadata (678 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.27)\n",
      "  Downloading llama_index_cli-0.1.12-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.27 (from llama-index==0.10.27)\n",
      "  Downloading llama_index_core-0.10.40-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index==0.10.27)\n",
      "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl.metadata (604 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index==0.10.27)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index==0.10.27)\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index==0.10.27)\n",
      "  Downloading llama_index_llms_openai-0.1.21-py3-none-any.whl.metadata (559 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index==0.10.27)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl.metadata (677 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.27)\n",
      "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl.metadata (715 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.27)\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.27)\n",
      "  Downloading llama_index_readers_file-0.1.23-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index==0.10.27)\n",
      "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.27)\n",
      "  Downloading openai-1.30.4-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27) (6.0.1)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading SQLAlchemy-2.0.30-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting httpx (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl.metadata (760 bytes)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting pandas (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading pandas-2.2.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading pillow-10.3.0-cp311-cp311-win_amd64.whl.metadata (9.4 kB)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27) (4.11.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.27)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.27)\n",
      "  Downloading pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.27)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.27)\n",
      "  Downloading llama_parse-0.4.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading multidict-6.0.5-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.27) (2.5)\n",
      "Collecting pydantic>=1.10 (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading pydantic-2.7.2-py3-none-any.whl.metadata (108 kB)\n",
      "     ---------------------------------------- 0.0/108.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 108.5/108.5 kB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: anyio in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27) (4.2.0)\n",
      "Collecting certifi (from httpx->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27) (1.3.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting click (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading regex-2024.5.15-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB ? eta 0:00:00\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.27)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27) (0.4.6)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27) (23.2)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.3 (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27)\n",
      "  Downloading pydantic_core-2.18.3-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.27->llama-index==0.10.27) (1.16.0)\n",
      "Downloading llama_index-0.10.27-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_index_agent_openai-0.2.5-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_core-0.10.40-py3-none-any.whl (15.4 MB)\n",
      "   ---------------------------------------- 0.0/15.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/15.4 MB 5.1 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.5/15.4 MB 6.7 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.0/15.4 MB 7.9 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.6/15.4 MB 9.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.4/15.4 MB 10.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.3/15.4 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 4.0/15.4 MB 12.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.8/15.4 MB 13.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.6/15.4 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.4/15.4 MB 14.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.2/15.4 MB 14.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.9/15.4 MB 14.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.8/15.4 MB 14.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.7/15.4 MB 14.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.5/15.4 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.3/15.4 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.1/15.4 MB 16.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.9/15.4 MB 17.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.8/15.4 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.5/15.4 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.4 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.4/15.4 MB 16.4 MB/s eta 0:00:00\n",
      "Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
      "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.7/2.0 MB 22.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.5/2.0 MB 19.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 15.8 MB/s eta 0:00:00\n",
      "Downloading llama_index_llms_openai-0.1.21-py3-none-any.whl (11 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl (5.8 kB)\n",
      "Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
      "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.23-py3-none-any.whl (36 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading aiohttp-3.9.5-cp311-cp311-win_amd64.whl (370 kB)\n",
      "   ---------------------------------------- 0.0/370.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 370.8/370.8 kB 22.5 MB/s eta 0:00:00\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "   ---------------------------------------- 0.0/147.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 147.9/147.9 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "   ---------------------------------------- 0.0/316.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 316.1/316.1 kB 19.1 MB/s eta 0:00:00\n",
      "Downloading llama_parse-0.4.3-py3-none-any.whl (7.7 kB)\n",
      "Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
      "   ---------------------------------------- 0.0/141.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 141.9/141.9 kB 8.8 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.6/75.6 kB ? eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.9/77.9 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.8/1.7 MB 27.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 22.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 15.5 MB/s eta 0:00:00\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.7/1.5 MB 23.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 19.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 16.0 MB/s eta 0:00:00\n",
      "Downloading openai-1.30.4-py3-none-any.whl (320 kB)\n",
      "   ---------------------------------------- 0.0/320.6 kB ? eta -:--:--\n",
      "   ------------------------------- ------- 256.0/320.6 kB 15.4 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 256.0/320.6 kB 15.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 276.5/320.6 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 320.6/320.6 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading pillow-10.3.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.8/2.5 MB 25.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.7/2.5 MB 21.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 18.0 MB/s eta 0:00:00\n",
      "Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 290.4/290.4 kB 17.5 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.9/64.9 kB ? eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.30-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.9/2.1 MB 18.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.7/2.1 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 16.5 MB/s eta 0:00:00\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading tiktoken-0.7.0-cp311-cp311-win_amd64.whl (799 kB)\n",
      "   ---------------------------------------- 0.0/799.0 kB ? eta -:--:--\n",
      "   --------------------------------------  798.7/799.0 kB 16.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 799.0/799.0 kB 16.8 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/15.8 MB 15.9 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.5/15.8 MB 15.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 2.3/15.8 MB 16.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 3.0/15.8 MB 17.3 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.8/15.8 MB 17.4 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.4/15.8 MB 16.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.2/15.8 MB 16.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.9/15.8 MB 16.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.7/15.8 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 7.5/15.8 MB 16.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.2/15.8 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 9.0/15.8 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.7/15.8 MB 16.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.3/15.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.1/15.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.8/15.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.5/15.8 MB 16.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.4/15.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.1/15.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.0/15.8 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading pandas-2.2.2-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.7/11.6 MB 23.8 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.5/11.6 MB 19.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.3/11.6 MB 18.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.2/11.6 MB 18.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.0/11.6 MB 18.3 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.9/11.6 MB 18.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.7/11.6 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.5/11.6 MB 18.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.0/11.6 MB 17.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.7/11.6 MB 17.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.6/11.6 MB 17.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.3/11.6 MB 17.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.6 MB 16.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.7/11.6 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.6 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 15.6 MB/s eta 0:00:00\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "   ---------------------------------------- 0.0/99.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 99.9/99.9 kB ? eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.5/50.5 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp311-cp311-win_amd64.whl (292 kB)\n",
      "   ---------------------------------------- 0.0/292.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 292.8/292.8 kB 18.8 MB/s eta 0:00:00\n",
      "Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.3/49.3 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading pydantic-2.7.2-py3-none-any.whl (409 kB)\n",
      "   ---------------------------------------- 0.0/409.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 409.5/409.5 kB 25.0 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.18.3-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.9/1.9 MB 18.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 17.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 12.0 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "   ---------------------------------------- 0.0/505.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 505.5/505.5 kB 16.0 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp311-cp311-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 269.0/269.0 kB 16.2 MB/s eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 345.4/345.4 kB 10.8 MB/s eta 0:00:00\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.7/76.7 kB ? eta 0:00:00\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 301.8/301.8 kB 18.2 MB/s eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: striprtf, pytz, dirtyjson, wrapt, urllib3, tzdata, tqdm, tenacity, regex, pypdf, pydantic-core, pillow, numpy, networkx, mypy-extensions, multidict, marshmallow, joblib, h11, greenlet, fsspec, frozenlist, distro, click, charset-normalizer, certifi, beautifulsoup4, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, pydantic, pandas, nltk, httpcore, deprecated, aiosignal, tiktoken, httpx, dataclasses-json, aiohttp, openai, llamaindex-py-client, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.12.2\n",
      "    Uninstalling beautifulsoup4-4.12.2:\n",
      "      Successfully uninstalled beautifulsoup4-4.12.2\n",
      "Successfully installed SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 beautifulsoup4-4.12.3 certifi-2024.2.2 charset-normalizer-3.3.2 click-8.1.7 dataclasses-json-0.6.6 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 frozenlist-1.4.1 fsspec-2024.5.0 greenlet-3.0.3 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 joblib-1.4.2 llama-index-0.10.27 llama-index-agent-openai-0.2.5 llama-index-cli-0.1.12 llama-index-core-0.10.40 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.21 llama-index-multi-modal-llms-openai-0.1.6 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.23 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.3 llamaindex-py-client-0.1.19 marshmallow-3.21.2 multidict-6.0.5 mypy-extensions-1.0.0 networkx-3.3 nltk-3.8.1 numpy-1.26.4 openai-1.30.4 pandas-2.2.2 pillow-10.3.0 pydantic-2.7.2 pydantic-core-2.18.3 pypdf-4.2.0 pytz-2024.1 regex-2024.5.15 requests-2.32.3 striprtf-0.0.26 tenacity-8.3.0 tiktoken-0.7.0 tqdm-4.66.4 typing-inspect-0.9.0 tzdata-2024.1 urllib3-2.2.1 wrapt-1.16.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "### uncomment to pip install\n",
    "#!pip install llama-index==0.10.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2e2ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-openai in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (0.1.21)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.24 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-llms-openai) (0.10.40)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.6.6)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.5.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.30.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.7.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.5.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (3.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (2.18.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.24->llama-index-llms-openai) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "### uncomment to pip install\n",
    "#!pip install llama-index-llms-openai==0.1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a68051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-openai==0.1.7\n",
      "  Downloading llama_index_embeddings_openai-0.1.7-py3-none-any.whl.metadata (603 bytes)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-embeddings-openai==0.1.7) (0.10.40)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (0.6.6)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (2024.5.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (0.1.19)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.30.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (10.3.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (8.3.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (2.7.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (2024.5.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (3.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (2.18.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jonca\\anaconda3\\envs\\llamindex\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.7) (1.16.0)\n",
      "Downloading llama_index_embeddings_openai-0.1.7-py3-none-any.whl (6.0 kB)\n",
      "Installing collected packages: llama-index-embeddings-openai\n",
      "  Attempting uninstall: llama-index-embeddings-openai\n",
      "    Found existing installation: llama-index-embeddings-openai 0.1.10\n",
      "    Uninstalling llama-index-embeddings-openai-0.1.10:\n",
      "      Successfully uninstalled llama-index-embeddings-openai-0.1.10\n",
      "Successfully installed llama-index-embeddings-openai-0.1.7\n"
     ]
    }
   ],
   "source": [
    "### uncomment to pip install\n",
    "#!pip install llama-index-embeddings-openai==0.1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab5f4f4a-5890-451c-8869-24606ef9f396",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "\n",
    "OPENAI_API_KEY = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc9b4f4-64d4-4266-9889-54db90e00ee9",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fca250",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae2a8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "To download this paper, below is the needed code:\n",
    "\n",
    "#!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf\n",
    "\n",
    "**Note**: The pdf file is included with this lesson. To access it, go to the `File` menu and select`Open...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c7f012d-dcd3-4881-a568-72dd27d79159",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48a301",
   "metadata": {},
   "source": [
    "## Define LLM and Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a537bc0-78ee-4dda-a43f-60fd80062df6",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0660ee-b231-4351-b158-d8ad023e00b5",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c7559",
   "metadata": {},
   "source": [
    "## Define Summary Index and Vector Index over the Same Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73d01b01-bc74-432a-8d92-07b9e86498b0",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9898d3f",
   "metadata": {},
   "source": [
    "## Define Query Engines and Set Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44cd7046-c714-4920-b077-b3ded917862f",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "vector_query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a1d6d75-247e-426a-8ef4-b49225c24796",
   "metadata": {
    "height": 285,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to MetaGPT\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2c152",
   "metadata": {},
   "source": [
    "## Define Router Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00734d7c-638a-4d63-ab1f-7f5a92a65119",
   "metadata": {
    "height": 217,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe3f0a76-68a8-444d-867f-d084bb3ff112",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: Useful for summarization questions related to MetaGPT.\n",
      "\u001b[0mThe document introduces MetaGPT, a meta-programming framework that enhances multi-agent systems based on Large Language Models (LLMs) through role specialization, workflow management, and efficient communication mechanisms. It outperforms existing approaches in software development tasks, with potential future enhancements like self-improvement mechanisms and multi-agent economies. The document details the development process of a software application named \"Drawing App\" using MetaGPT, outlining the roles of various agents in the software development lifecycle. It discusses the use of Python libraries for GUI creation and testing, emphasizing the importance of team members being familiar with the project's libraries. Additionally, it explores MetaGPT's performance in generating executable code, addressing challenges like efficiently using context and reducing hallucinations. Ethical concerns related to MetaGPT, such as unemployment and data security, are also discussed, providing a comprehensive overview of AI-driven software development.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3fedea0-f2a9-46bb-8aaf-287df65b8fff",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af8c31b3-8e22-4ad9-9825-b8de21bd03c0",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: Useful for summarization questions related to MetaGPT.\n",
      "\u001b[0mAgents share information with other agents through a shared message pool and a subscription mechanism. This shared message pool allows agents to publish structured messages and access messages from other agents transparently. The subscription mechanism enables agents to subscribe to relevant messages based on their profiles, ensuring they can extract necessary information efficiently. This structured communication interface enhances communication efficiency by allowing agents to focus on task-related information based on their roles.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"How do agents share information with other agents?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed060ee",
   "metadata": {},
   "source": [
    "## Let's put everything together\n",
    "The code you ran through above is moved to get_router_query_engine.  Nice.  All you need to do now is send in the document name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8f92e0b-1c54-489b-b8dd-41ebaafb380a",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from utils import get_router_query_engine\n",
    "\n",
    "query_engine = get_router_query_engine(\"metagpt.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec1a43f3-77dc-472a-8adc-56551c00a0ff",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: Ablation study results are specific context from the MetaGPT paper, making choice 2 the most relevant..\n",
      "\u001b[0mThe ablation study results provide insights into the impact of removing certain components or features from a system or model. This analysis helps in understanding the contribution and significance of individual elements towards the overall performance or functionality of the system.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6dd4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
